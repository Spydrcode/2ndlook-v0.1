#!/usr/bin/env node

/**
 * Smoke test for snapshot generation
 * 
 * Tests the complete pipeline:
 * 1. Ingest demo estimates
 * 2. Bucket estimates
 * 3. Generate snapshot (deterministic or orchestrated based on SNAPSHOT_MODE)
 * 4. Validate SnapshotResult schema
 * 
 * Usage:
 *   npx ts-node --compiler-options '{"module":"CommonJS"}' scripts/smoke-run-snapshot.ts
 * 
 * Prerequisites:
 *   - SUPABASE_URL and SUPABASE_ANON_KEY in .env.local
 *   - Demo data in src/demo-data/estimates-demo.csv
 *   - Optional: OPENAI_API_KEY for orchestrated mode
 */

import { createClient } from "@supabase/supabase-js";
import { readFileSync } from "fs";
import { join } from "path";
import { config } from "dotenv";

// Load environment
config({ path: ".env.local" });

const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL;
const SUPABASE_ANON_KEY = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY;
const SNAPSHOT_MODE = process.env.SNAPSHOT_MODE || "deterministic";

if (!SUPABASE_URL || !SUPABASE_ANON_KEY) {
  console.error("‚ùå Missing environment variables:");
  console.error("   NEXT_PUBLIC_SUPABASE_URL and NEXT_PUBLIC_SUPABASE_ANON_KEY required");
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_ANON_KEY);

interface SnapshotResult {
  meta: {
    snapshot_id: string;
    source_id: string;
    generated_at: string;
    estimate_count: number;
    confidence_level: "low" | "medium" | "high";
  };
  demand: {
    weekly_volume: { week: string; count: number }[];
    price_distribution: { band: string; count: number }[];
  };
  decision_latency: {
    distribution: { band: string; count: number }[];
  };
}

function validateSnapshotResult(result: unknown): result is SnapshotResult {
  if (!result || typeof result !== "object") return false;

  const r = result as Record<string, unknown>;

  // Validate meta
  if (!r.meta || typeof r.meta !== "object") return false;
  const meta = r.meta as Record<string, unknown>;
  if (typeof meta.snapshot_id !== "string") return false;
  if (typeof meta.source_id !== "string") return false;
  if (typeof meta.generated_at !== "string") return false;
  if (typeof meta.estimate_count !== "number") return false;
  if (!["low", "medium", "high"].includes(meta.confidence_level as string)) return false;

  // Validate demand
  if (!r.demand || typeof r.demand !== "object") return false;
  const demand = r.demand as Record<string, unknown>;
  if (!Array.isArray(demand.weekly_volume)) return false;
  if (!Array.isArray(demand.price_distribution)) return false;

  // Validate decision_latency
  if (!r.decision_latency || typeof r.decision_latency !== "object") return false;
  const decisionLatency = r.decision_latency as Record<string, unknown>;
  if (!Array.isArray(decisionLatency.distribution)) return false;

  return true;
}

async function runSmokeTest() {
  console.log("üöÄ Starting snapshot smoke test...\n");
  console.log(`Mode: ${SNAPSHOT_MODE}\n`);

  try {
    // Step 1: Create test source
    console.log("üìù Step 1: Creating test source...");
    
    const { data: authData } = await supabase.auth.getUser();
    if (!authData?.user) {
      console.error("‚ùå Not authenticated. Please sign in first.");
      process.exit(1);
    }

    const user_id = authData.user.id;
    const source_name = `Smoke Test ${new Date().toISOString()}`;

    const { data: source, error: sourceError } = await supabase
      .from("sources")
      .insert({
        user_id,
        source_type: "csv",
        source_name,
        status: "pending",
      })
      .select("id")
      .single();

    if (sourceError || !source) {
      throw new Error(`Failed to create source: ${sourceError?.message}`);
    }

    const source_id = source.id;
    console.log(`‚úÖ Source created: ${source_id}\n`);

    // Step 2: Load demo data
    console.log("üìÇ Step 2: Loading demo data...");
    
    // Try .demo/estimates-demo.csv first, fallback to src/demo-data
    let demoPath = join(process.cwd(), ".demo", "estimates-demo.csv");
    let csvContent: string;
    
    try {
      csvContent = readFileSync(demoPath, "utf-8");
      console.log(`‚úÖ Demo data loaded from .demo/ (${csvContent.split("\n").length - 1} rows)\n`);
    } catch {
      // Fallback to old location
      demoPath = join(process.cwd(), "src", "demo-data", "estimates-demo.csv");
      try {
        csvContent = readFileSync(demoPath, "utf-8");
        console.log(`‚úÖ Demo data loaded from src/demo-data/ (${csvContent.split("\n").length - 1} rows)\n`);
      } catch (error) {
        console.error("‚ùå Demo data not found. Run: npm run demo:generate");
        console.error(`   Expected at: ${join(process.cwd(), ".demo", "estimates-demo.csv")}`);
        process.exit(1);
      }
    }

    // Step 3: Ingest (simplified - assumes API would handle this)
    console.log("üì• Step 3: Ingesting estimates...");
    console.log("   (Skipping - assumes demo data already ingested)\n");

    // For smoke test, we'll mock the ingestion by directly inserting
    // In production, this would go through /api/ingest
    const lines = csvContent.trim().split("\n");
    
    const estimates = lines.slice(1).map((line) => {
      const values = line.split(",");
      return {
        source_id,
        estimate_id: values[0],
        created_at: values[1],
        closed_at: values[2],
        amount: Number.parseFloat(values[3]),
        status: values[4] as "closed" | "accepted",
        job_type: values[5] || null,
      };
    });

    const { error: ingestError } = await supabase
      .from("estimates_normalized")
      .insert(estimates);

    if (ingestError) {
      throw new Error(`Failed to ingest estimates: ${ingestError.message}`);
    }

    console.log(`‚úÖ Ingested ${estimates.length} estimates\n`);

    // Update source status
    await supabase
      .from("sources")
      .update({ status: "ingested" })
      .eq("id", source_id);

    // Step 4: Bucket
    console.log("üóÇÔ∏è  Step 4: Bucketing estimates...");
    
    if (!SUPABASE_URL) {
      console.log("   Skipping bucket step (no SUPABASE_URL)\n");
    } else {
      const bucketResponse = await fetch(`${SUPABASE_URL.replace(/\/$/, "")}/api/bucket`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${SUPABASE_ANON_KEY}`,
        },
        body: JSON.stringify({ source_id }),
      });

      if (!bucketResponse.ok) {
        // Fallback: bucket directly if API not available
        console.log("   API not available, skipping bucket step");
        console.log("   (In production, call POST /api/bucket)\n");
      } else {
        console.log("‚úÖ Estimates bucketed\n");
      }
    }

    // Step 5: Generate snapshot
    console.log("üì∏ Step 5: Generating snapshot...");
    
    if (!SUPABASE_URL) {
      console.error("‚ùå Cannot generate snapshot without SUPABASE_URL");
      process.exit(1);
    }
    
    const snapshotResponse = await fetch(`${SUPABASE_URL.replace(/\/$/, "")}/api/snapshot`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${SUPABASE_ANON_KEY}`,
      },
      body: JSON.stringify({ source_id }),
    });

    if (!snapshotResponse.ok) {
      // Fallback: generate directly if API not available
      console.log("   API not available, skipping snapshot generation");
      console.log("   (In production, call POST /api/snapshot)\n");
      console.log("‚ö†Ô∏è  Smoke test incomplete - API routes not accessible");
      console.log("   This is expected in development mode");
      console.log("   To test fully, run: npm run dev\n");
      
      // Cleanup
      await supabase.from("sources").delete().eq("id", source_id);
      
      return;
    }

    const snapshotData = await snapshotResponse.json();
    const snapshot_id = snapshotData.snapshot_id;

    console.log(`‚úÖ Snapshot generated: ${snapshot_id}\n`);

    // Step 6: Validate schema
    console.log("‚úîÔ∏è  Step 6: Validating SnapshotResult schema...");
    
    const { data: snapshot, error: fetchError } = await supabase
      .from("snapshots")
      .select("result")
      .eq("id", snapshot_id)
      .single();

    if (fetchError || !snapshot) {
      throw new Error(`Failed to fetch snapshot: ${fetchError?.message}`);
    }

    const isValid = validateSnapshotResult(snapshot.result);

    if (!isValid) {
      console.error("‚ùå SnapshotResult schema validation FAILED");
      console.error("   Result:", JSON.stringify(snapshot.result, null, 2));
      process.exit(1);
    }

    console.log("‚úÖ SnapshotResult schema is valid\n");

    // Success summary
    console.log("üéâ Smoke test PASSED!\n");
    console.log("Summary:");
    console.log(`  - Mode: ${SNAPSHOT_MODE}`);
    console.log(`  - Source ID: ${source_id}`);
    console.log(`  - Snapshot ID: ${snapshot_id}`);
    console.log(`  - Estimate Count: ${snapshot.result.meta.estimate_count}`);
    console.log(`  - Confidence Level: ${snapshot.result.meta.confidence_level}`);
    console.log();

    // Cleanup (optional)
    console.log("üßπ Cleaning up test data...");
    await supabase.from("snapshots").delete().eq("id", snapshot_id);
    await supabase.from("estimates_normalized").delete().eq("source_id", source_id);
    await supabase.from("estimate_buckets").delete().eq("source_id", source_id);
    await supabase.from("sources").delete().eq("id", source_id);
    console.log("‚úÖ Cleanup complete\n");

  } catch (error) {
    console.error("\n‚ùå Smoke test FAILED:");
    console.error(error instanceof Error ? error.message : "Unknown error");
    process.exit(1);
  }
}

// Run
runSmokeTest().catch((error) => {
  console.error("Fatal error:", error);
  process.exit(1);
});
